{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# YOUR FIRST LAB\n",
    "### Please read this section. This is valuable to get you prepared, even if it's a long read -- it's important stuff.\n",
    "\n",
    "## Your first Frontier LLM Project\n",
    "\n",
    "Let's build a useful LLM solution - in a matter of minutes.\n",
    "\n",
    "By the end of this course, you will have built an autonomous Agentic AI solution with 7 agents that collaborate to solve a business problem. All in good time! We will start with something smaller...\n",
    "\n",
    "Our goal is to code a new kind of Web Browser. Give it a URL, and it will respond with a summary. The Reader's Digest of the internet!!\n",
    "\n",
    "Before starting, you should have completed the setup for [PC](../SETUP-PC.md) or [Mac](../SETUP-mac.md) and you hopefully launched this jupyter lab from within the project root directory, with your environment activated.\n",
    "\n",
    "## If you're new to Jupyter Lab\n",
    "\n",
    "Welcome to the wonderful world of Data Science experimentation! Once you've used Jupyter Lab, you'll wonder how you ever lived without it. Simply click in each \"cell\" with code in it, such as the cell immediately below this text, and hit Shift+Return to execute that cell. As you wish, you can add a cell with the + button in the toolbar, and print values of variables, or try out variations.  \n",
    "\n",
    "I've written a notebook called [Guide to Jupyter](Guide%20to%20Jupyter.ipynb) to help you get more familiar with Jupyter Labs, including adding Markdown comments, using `!` to run shell commands, and `tqdm` to show progress.\n",
    "\n",
    "## If you're new to the Command Line\n",
    "\n",
    "Please see these excellent guides: [Command line on PC](https://chatgpt.com/share/67b0acea-ba38-8012-9c34-7a2541052665) and [Command line on Mac](https://chatgpt.com/canvas/shared/67b0b10c93a081918210723867525d2b).  \n",
    "\n",
    "## If you'd prefer to work in IDEs\n",
    "\n",
    "If you're more comfortable in IDEs like VSCode, Cursor or PyCharm, they both work great with these lab notebooks too.  \n",
    "If you'd prefer to work in VSCode, [here](https://chatgpt.com/share/676f2e19-c228-8012-9911-6ca42f8ed766) are instructions from an AI friend on how to configure it for the course.\n",
    "\n",
    "## If you'd like to brush up your Python\n",
    "\n",
    "I've added a notebook called [Intermediate Python](Intermediate%20Python.ipynb) to get you up to speed. But you should give it a miss if you already have a good idea what this code does:    \n",
    "`yield from {book.get(\"author\") for book in books if book.get(\"author\")}`\n",
    "\n",
    "## I am here to help\n",
    "\n",
    "If you have any problems at all, please do reach out.  \n",
    "I'm available through the platform, or at ed@edwarddonner.com, or at https://www.linkedin.com/in/eddonner/ if you'd like to connect (and I love connecting!)  \n",
    "And this is new to me, but I'm also trying out X/Twitter at [@edwarddonner](https://x.com/edwarddonner) - if you're on X, please show me how it's done üòÇ  \n",
    "\n",
    "## More troubleshooting\n",
    "\n",
    "Please see the [troubleshooting](troubleshooting.ipynb) notebook in this folder to diagnose and fix common problems. At the very end of it is a diagnostics script with some useful debug info.\n",
    "\n",
    "## For foundational technical knowledge (eg Git, APIs, debugging) \n",
    "\n",
    "If you're relatively new to programming -- I've got your back! While it's ideal to have some programming experience for this course, there's only one mandatory prerequisite: plenty of patience. üòÅ I've put together a set of self-study guides that cover Git and GitHub, APIs and endpoints, beginner python and more.\n",
    "\n",
    "This covers Git and GitHub; what they are, the difference, and how to use them:  \n",
    "https://github.com/ed-donner/agents/blob/main/guides/03_git_and_github.ipynb\n",
    "\n",
    "This covers technical foundations:  \n",
    "ChatGPT vs API; taking screenshots; Environment Variables; Networking basics; APIs and endpoints:  \n",
    "https://github.com/ed-donner/agents/blob/main/guides/04_technical_foundations.ipynb\n",
    "\n",
    "This covers Python for beginners, and making sure that a `NameError` never trips you up:  \n",
    "https://github.com/ed-donner/agents/blob/main/guides/06_python_foundations.ipynb\n",
    "\n",
    "This covers the essential techniques for figuring out errors:  \n",
    "https://github.com/ed-donner/agents/blob/main/guides/08_debugging.ipynb\n",
    "\n",
    "And you'll find other useful guides in the same folder in GitHub. Some information applies to my other Udemy course (eg Async Python) but most of it is very relevant for LLM engineering.\n",
    "\n",
    "## If this is old hat!\n",
    "\n",
    "If you're already comfortable with today's material, please hang in there; you can move swiftly through the first few labs - we will get much more in depth as the weeks progress. Ultimately we will fine-tune our own LLM to compete with OpenAI!\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Please read - important note</h2>\n",
    "            <span style=\"color:#900;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations. If you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">This code is a live resource - keep an eye out for my emails</h2>\n",
    "            <span style=\"color:#f71;\">I push updates to the code regularly. As people ask questions, I add more examples or improved commentary. As a result, you'll notice that the code below isn't identical to the videos. Everything from the videos is here; but I've also added better explanations and new models like DeepSeek. Consider this like an interactive book.<br/><br/>\n",
    "                I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business value of these exercises</h2>\n",
    "            <span style=\"color:#181;\">A final thought. While I've designed these notebooks to be educational, I've also tried to make them enjoyable. We'll do fun things like have LLMs tell jokes and argue with each other. But fundamentally, my goal is to teach skills you can apply in business. I'll explain business implications as we go, and it's worth keeping this in mind: as you build experience with models and techniques, think of ways you could put this into action at work today. Please do contact me if you'd like to discuss more or if you have ideas to bounce off me.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b2a8-6384-4316-8aaa-5e519fca4254",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI (or Ollama)\n",
    "\n",
    "The next cell is where we load in the environment variables in your `.env` file and connect to OpenAI.  \n",
    "\n",
    "If you'd like to use free Ollama instead, please see the README section \"Free Alternative to Paid APIs\", and if you're not sure how to do this, there's a full solution in the solutions folder (day1_with_ollama.ipynb).\n",
    "\n",
    "## Troubleshooting if you have problems:\n",
    "\n",
    "Head over to the [troubleshooting](troubleshooting.ipynb) notebook in this folder for step by step code to identify the root cause and fix it!\n",
    "\n",
    "If you make a change, try restarting the \"Kernel\" (the python process sitting behind this notebook) by Kernel menu >> Restart Kernel and Clear Outputs of All Cells. Then try this notebook again, starting at the top.\n",
    "\n",
    "Or, contact me! Message me or email ed@edwarddonner.com and we will get this to work.\n",
    "\n",
    "Any concerns about API costs? See my notes in the README - costs should be minimal, and you can control it at every point. You can also use Ollama as a free alternative, which we discuss during Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019974d9-f3ad-4a8a-b5f9-0a3719aea2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "# If this doesn't work, try Kernel menu >> Restart Kernel and Clear Outputs Of All Cells, then run the cells from the top of this notebook down.\n",
    "# If it STILL doesn't work (horrors!) then please see the Troubleshooting notebook in this folder for full instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc84b-0815-4f40-99ab-d9a5da6bda91",
   "metadata": {},
   "source": [
    "# Let's make a quick call to a Frontier model to get started, as a preview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58394bf-1e45-46af-9bfd-01e24da6f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome! I'm glad you're here. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\n",
    "\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa190e5-cb31-456a-96cc-db109919cd78",
   "metadata": {},
   "source": [
    "## OK onwards with our first project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e793b2-6775-426a-a139-4848291d0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google\n",
      "About\n",
      "Store\n",
      "Gmail\n",
      "Images\n",
      "Sign in\n",
      "See more\n",
      "Delete\n",
      "Delete\n",
      "Report inappropriate predictions\n",
      "Advertising\n",
      "Business\n",
      "How Search works\n",
      "Applying AI towards science and the environment\n",
      "Privacy\n",
      "Terms\n",
      "Settings\n",
      "Search settings\n",
      "Advanced search\n",
      "Your data in Search\n",
      "Search history\n",
      "Search help\n",
      "Send feedback\n",
      "Dark theme: Off\n",
      "Google apps\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "ed = Website(\"https://google.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT4o have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26448ec4-5c00-4204-baec-7df91d11ff2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Google\n",
      "The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
      "\n",
      "About\n",
      "Store\n",
      "Gmail\n",
      "Images\n",
      "Sign in\n",
      "See more\n",
      "Delete\n",
      "Delete\n",
      "Report inappropriate predictions\n",
      "Advertising\n",
      "Business\n",
      "How Search works\n",
      "Applying AI towards science and the environment\n",
      "Privacy\n",
      "Terms\n",
      "Settings\n",
      "Search settings\n",
      "Advanced search\n",
      "Your data in Search\n",
      "Search history\n",
      "Search help\n",
      "Send feedback\n",
      "Dark theme: Off\n",
      "Google apps\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the mighty GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f25dcd35-0cd0-4235-9f64-ac37ed9eaaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ed95c5-7001-47de-a36d-1d6673b403ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, we're diving deep into the world of advanced mathematics, huh? Well, brace yourself: 2 + 2 equals a solid 4. Shocking, I know!\n"
     ]
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with system and user messages:\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for GPT-4o-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36478464-39ee-485c-9f3f-6a4e458dbc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Google\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nAbout\\nStore\\nGmail\\nImages\\nSign in\\nSee more\\nDelete\\nDelete\\nReport inappropriate predictions\\nAdvertising\\nBusiness\\nHow Search works\\nApplying AI towards science and the environment\\nPrivacy\\nTerms\\nSettings\\nSearch settings\\nAdvanced search\\nYour data in Search\\nSearch history\\nSearch help\\nSend feedback\\nDark theme: Off\\nGoogle apps'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "## Time to bring it together - the API for OpenAI is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Summary of Edward Donner's Website\\n\\nEdward Donner's website serves as a personal hub for his professional interests and activities, primarily focusing on his work with language models (LLMs) and AI technology. As the co-founder and CTO of Nebula.io, he aims to leverage AI in talent management to help individuals discover their potential. Previously, he founded the AI startup untapt, which was acquired in 2021.\\n\\nThe website features his enthusiasm for coding, electronic music, and community engagement through platforms like Hacker News. \\n\\n## Announcements\\n- **May 28, 2025**: Launching courses aimed at training individuals to become experts and leaders in LLM technology.\\n- **May 18, 2025**: Hosting a 2025 AI Executive Briefing.\\n- **April 21, 2025**: Introducing the Complete Agentic AI Engineering Course.\\n- **January 23, 2025**: Offering a hands-on LLM Workshop focused on agents and associated resources. \\n\\nVisitors are encouraged to connect with him and stay updated through various social media and newsletter subscriptions.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Website Summary: Edward Donner\n",
       "\n",
       "**Overview**  \n",
       "This website belongs to Ed Donner, a technology enthusiast focused on coding and experiments with large language models (LLMs). He is the co-founder and CTO of Nebula.io, a company leveraging AI to assist individuals in discovering their potential and improving talent management for recruiters. Previously, he founded the AI startup untapt, which was acquired in 2021.\n",
       "\n",
       "**Interests**  \n",
       "Ed has interests in DJing and electronic music production, although he notes he is out of practice. He often engages with the Hacker News community.\n",
       "\n",
       "**Key Offerings**  \n",
       "- **Connect Four**: An arena designed for LLMs to compete in diplomacy and strategy.\n",
       "- Expertise in proprietary LLMs verticalized for talent with patented matching models.\n",
       "\n",
       "**Recent Announcements**  \n",
       "- **May 28, 2025**: Introduction of courses aimed at developing leaders and experts in LLMs.\n",
       "- **May 18, 2025**: Announcement of the 2025 AI Executive Briefing.\n",
       "- **April 21, 2025**: Launch of \"The Complete Agentic AI Engineering Course.\"\n",
       "- **January 23, 2025**: Hosting of an LLM workshop focusing on hands-on experience with agent technologies. \n",
       "\n",
       "**Connect**  \n",
       "Visitors are encouraged to connect with Ed and subscribe to his newsletter for further updates."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Let's try more websites\n",
    "\n",
    "Note that this will only work on websites that can be scraped using this simplistic approach.\n",
    "\n",
    "Websites that are rendered with Javascript, like React apps, won't show up. See the community-contributions folder for a Selenium implementation that gets around this. You'll need to read up on installing Selenium (ask ChatGPT!)\n",
    "\n",
    "Also Websites protected with CloudFront (and similar) may give 403 errors - many thanks Andy J for pointing this out.\n",
    "\n",
    "But many websites will work just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Website Summary: CNN \n",
       "\n",
       "CNN is a global news platform that covers a wide range of topics including U.S. and international news, politics, business, health, entertainment, science, and sports. It provides timely updates on significant events and issues worldwide.\n",
       "\n",
       "## Key News Highlights:\n",
       "- **Trump Administration Actions**: The Trump administration has been involved in several controversial actions including a ban on visas for new international students at Harvard and various immigration policies affecting migrant children and adults.\n",
       "- **Israel-Hamas Conflict**: Reports highlight tensions in Gaza, with analysis pointing to Israeli gunfire during aid operations, amid ongoing violence in the region.\n",
       "- **Ukraine-Russia War**: Ongoing coverage of the war includes reports on drone strikes affecting key Russian air bases and the rising casualty figures.\n",
       "- **Crowd Crush Incident in India**: A tragic crowd crush occurred outside a cricket stadium, resulting in at least 11 deaths.\n",
       "- **Cultural Moments**: Celebrations and reunions from the iconic film \"Back to the Future,\" including commentary from its stars, are highlighted in entertainment news.\n",
       "\n",
       "CNN also features a variety of other content, including investigative journalism, opinion pieces, personal stories, and multimedia content such as videos and podcasts. The platform encourages user feedback and engagement regarding advertisements and technical experiences. \n",
       "\n",
       "Overall, CNN aims to inform and engage its audience with up-to-date reporting on critical global issues."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Anthropic Website\n",
       "\n",
       "The **Anthropic** website primarily focuses on its AI model, **Claude**, and related products, emphasizing safety and human benefit in AI development. \n",
       "\n",
       "### Key Sections:\n",
       "\n",
       "- **Claude Models**: \n",
       "  - Introduction of **Claude Opus 4**, the latest and most advanced AI model.\n",
       "  - Other models mentioned include **Claude Sonnet 4** and **Claude Haiku 3.5**, noted for their capabilities in coding and AI applications.\n",
       "\n",
       "- **Research & Initiatives**: \n",
       "  - Emphasis on AI safety and the responsible development of AI technologies.\n",
       "  - Topics like the **Anthropic Economic Index** and a commitment to transparency are highlighted.\n",
       "  - The site discusses **alignment science** and interpretability, showcasing models' internal processes.\n",
       "\n",
       "- **News & Updates**:\n",
       "  - Announcement of **ISO 42001 certification**, reflecting their commitment to quality and safety.\n",
       "  - Content on future updates and capabilities of upcoming models.\n",
       "\n",
       "- **Learning & Development**:\n",
       "  - Features the **Anthropic Academy** for building and learning about AI applications using Claude.\n",
       "  - Resources aimed at developers to explore building with Claude and APIs.\n",
       "\n",
       "- **Corporate Information**: \n",
       "  - Information about the company's mission to ensure that AI serves humanity positively, emphasizing the importance of considering societal impacts.\n",
       "\n",
       "Overall, the website reflects Anthropic's focus on advanced AI technology while prioritizing safety, transparency, and ethical considerations in the development and application of AI systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951be1a-7f1b-448f-af1f-845978e47e2c",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise, you experienced calling the Cloud API of a Frontier Model (a leading model at the frontier of AI) for the first time. We will be using APIs like OpenAI at many stages in the course, in addition to building our own LLMs.\n",
    "\n",
    "More specifically, we've applied this to Summarization - a classic Gen AI use case to make a summary. This can be applied to any business vertical - summarizing the news, summarizing financial performance, summarizing a resume in a cover letter - the applications are limitless. Consider how you could apply Summarization in your business, and try prototyping a solution.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue - now try yourself</h2>\n",
    "            <span style=\"color:#900;\">Use the cell below to make your own simple commercial example. Stick with the summarization use case for now. Here's an idea: write something that will take the contents of an email, and will suggest an appropriate short subject line for the email. That's the kind of feature that might be built into a commercial email tool.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00743dac-0e70-45b7-879a-d7293a6f68a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of the Email: \"The AI Engineering Stack\"\n",
       "\n",
       "- **Sender**: The Pragmatic Engineer (Gergely Orosz)\n",
       "- **Date**: May 20, 2025\n",
       "- **Topic**: Overview of AI Engineering and its distinctions from traditional ML engineering, featuring insights from Chip Huyen's book *AI Engineering*.\n",
       "\n",
       "## Key Points:\n",
       "- **AI Engineering Stack**: Described in terms of three layers:\n",
       "  - **Application Development**: Focuses on using models to develop applications, emphasizing prompt engineering and user interfaces.\n",
       "  - **Model Development**: Involves creating and optimizing models, less about traditional training and more about model adaptation.\n",
       "  - **Infrastructure**: Provides the necessary tools for model serving and data management.\n",
       "\n",
       "- **Differences Between AI and ML Engineering**:\n",
       "  - AI engineering prioritizes adaptation of existing large models over building new ones.\n",
       "  - Works with larger models requiring significant computing resources, which impacts latency and performance.\n",
       "\n",
       "- **Emerging Interfacing Techniques**: New interfaces for AI applications have emerged, allowing for easier integration and user interaction, pushing AI engineering toward a full-stack development approach.\n",
       "\n",
       "- **Call to Action**: Encourages readers to dive deeper into AI engineering, highlighting the evolving landscape of roles, responsibilities, and skills in this growing field.\n",
       "\n",
       "## Additional Information:\n",
       "- Upcoming events include a live podcast recording at the LDX3 conference in London featuring discussions on AI at Shopify.\n",
       "- A recommendation to explore Chip Huyen's book for more comprehensive learning on AI engineering topics. \n",
       "\n",
       "This email serves to enlighten subscribers about the increasing significance of AI engineering and how professionals can adapt to harness this emerging field."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of emails \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "user_prompt = \"\"\"\n",
    "The AI Engineering Stack\n",
    "1 message\n",
    "The Pragmatic Engineer <pragmaticengineer+deepdives@substack.com> Tue, May 20, 2025 at 8:28 AM\n",
    "Reply-To: The Pragmatic Engineer\n",
    "<reply+2pncgo&4kt3&&b89235ca75ab8ca4d63b517b854088e961d0ffce9a44ddd303cb543b0f2e2bf1@mg1.substack.com>\n",
    "To: me@gmail.com\n",
    "Forwarded this email? Subscribe here for more\n",
    "Hi ‚Äì this is Gergely with the monthly, free issue of the Pragmatic Engineer\n",
    "Newsletter. In every issue, I cover challenges at Big Tech and startups\n",
    "through the lens of engineering managers and senior engineers. If you‚Äôve\n",
    "been forwarded this email, you can subscribe here.\n",
    "Many subscribers expense this newsletter to their learning and development\n",
    "budget. If you have such a budget, here‚Äôs an email you could send to your\n",
    "manager.\n",
    "The AI Engineering Stack\n",
    "Three layers of the AI stack, how AI engineering is different from ML\n",
    "engineering and fullstack engineering, and more. An excerpt from\n",
    "the book AI Engineering by Chip Huyen\n",
    "GERGELY OROSZ AND CHIP HUYEN\n",
    "MAY 20\n",
    "READ IN APP\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 1/22\n",
    "Before we start: on Monday, 16 June, I‚Äôll be recording an episode of the\n",
    "Pragmatic Engineer podcast live at the LDX3 conference in London, with\n",
    "special guest, Farhan Thawar, who is Shopify‚Äôs Head of Engineering. It‚Äôs the\n",
    "closing session of the conference on that day, and it‚Äôd be great if you can join,\n",
    "should you be at the event. During the live pod recording, Farhan and me will\n",
    "cover:\n",
    "How Shopify‚Äôs ‚ÄúReflexive AI usage‚Äù approach is changing how their\n",
    "engineering team works\n",
    "How Shopify iterates as fast as it does as a full-remote company\n",
    "An unconventional approach to engineering career growth: mastery and\n",
    "craft\n",
    "‚Ä¶ and more on how one of the most unconventional tech companies\n",
    "operates and gets stuff done\n",
    "If you can, why not join us live at LDX3. I will also deliver a keynote at the\n",
    "conference, and you can meet the The Pragmatic Engineer team, including\n",
    "myself, Elin, and Dominic, too. If you won‚Äôt be there, the recording will be\n",
    "published as an episode of The Pragmatic Engineer Podcast after the event.\n",
    "With that, let‚Äôs get into the AI Engineering Stack.\n",
    "‚ÄúAI Engineering‚Äù is a term that didn‚Äôt even exist two years ago, but today, AI\n",
    "engineers are in high demand. Companies like Meta, Google, and Amazon,\n",
    "offer higher base salaries for these roles than ‚Äúregular‚Äù software engineers\n",
    "get, while AI startups and scaleups are scrambling to hire them.\n",
    "However, closer inspection reveals AI engineers are often regular software\n",
    "engineers who have mastered the basics of large language models (LLM),\n",
    "such as working with them and integrating them.\n",
    "So far, the best book I‚Äôve found on this hot topic is AI Engineering by Chip\n",
    "Huyen, published in January by O‚ÄôReilly. Chip has worked as a researcher at\n",
    "Netflix, was a core developer at NVIDIA (building NeMo, NVIDIA‚Äôs GenAI\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 2/22\n",
    "framework), and cofounded Claypot AI. She has also taught machine learning\n",
    "(ML) at Stanford University.\n",
    "In February, we published a podcast episode with Chip about what AI\n",
    "engineering is, how it differs from ML engineering, and the techniques AI\n",
    "engineers should be familiar with.\n",
    "For this article, I asked Chip if she would be willing to share an excerpt of her\n",
    "book, and she has generously agreed. This covers what an AI engineering\n",
    "stack looks like: the one us software engineers must become expert in order\n",
    "to be an AI engineer.\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 3/22\n",
    "My AI Engineering book by Chip Huyen\n",
    "In today‚Äôs issue we get into:\n",
    ". Three layers of the AI stack. Application development, model\n",
    "development, infrastructure.\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 4/22\n",
    ". AI engineering versus ML engineering. Similarities and differences,\n",
    "including how inference optimization evaluation matters more in AI\n",
    "engineering, and ML knowledge being more of a nice-to-have and less\n",
    "of a must-have.\n",
    ". Application development in AI engineering. The three main focus\n",
    "areas: evaluation, prompt engineering, and AI interfaces.\n",
    ". AI Engineering versus full-stack engineering. ‚ÄúAI engineering is just\n",
    "software engineering with AI models thrown in the stack.‚Äù\n",
    "If you find this excerpt useful, you‚Äôll likely get value from the rest of the book,\n",
    "which can be purchased as an ebook or a physical copy. This newsletter has\n",
    "also published some deepdives which you may find useful for getting into AI\n",
    "engineering:\n",
    "AI Engineering in the real world ‚Äì stories from 7 software engineersturned AI engineers\n",
    "Building, launching, and scaling ChatGPT Images ‚Äì insights from\n",
    "OpenAI‚Äôs engineering team\n",
    "Building Windsurf ‚Äì and the engineering challenges behind it\n",
    "As with all recommendations in this newsletter, I have not been paid to\n",
    "mention this book, and no links in this article are affiliates. For more details,\n",
    "see my ethics statement.\n",
    "The bottom of this article could be cut off in some email clients. Read the full\n",
    "article uninterrupted, online.\n",
    "Read the full article online\n",
    "With that, let‚Äôs get into it:\n",
    "This excerpt is from Chapter 1 of AI Engineering, by Chip Huyen. Copyright ¬©\n",
    "2025 Chip Huyen. Published by O'Reilly Media, Inc. Used with permission.\n",
    "AI engineering‚Äôs rapid growth has induced an incredible amount of hype and\n",
    "FOMO (fear of missing out). The number of new tools, techniques, models,\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 5/22\n",
    "and applications introduced every day can be overwhelming. Instead of trying\n",
    "to keep up with these constantly shifting sands, let‚Äôs inspect the fundamental\n",
    "building blocks of AI engineering.\n",
    "To understand AI engineering, it‚Äôs important to recognize that AI engineering\n",
    "evolved out of ML engineering. When a company starts experimenting with\n",
    "foundation models, it‚Äôs natural that its existing ML team should lead the effort.\n",
    "Some companies treat AI engineering the same as ML engineering, as shown\n",
    "in Figure 1-12.\n",
    "Figure 1-12. Many companies put AI engineering and ML\n",
    "engineering under the same umbrella, as shown in job\n",
    "headlines on LinkedIn from December 17, 2023.\n",
    "Some companies have separate job descriptions for AI engineering, as\n",
    "shown in Figure 1-13.\n",
    "Regardless of where organizations position AI engineers and ML engineers,\n",
    "their roles significantly overlap. Existing ML engineers can add AI engineering\n",
    "to their list of skills to enhance their job prospects, and there are also AI\n",
    "engineers with no ML experience.\n",
    "To best understand AI engineering and how it differs from traditional ML\n",
    "engineering, the following section breaks down the different layers of the AI\n",
    "application building process, and looks at the role each layer plays in AI and\n",
    "ML engineering.\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 6/22\n",
    "Figure 1-13. Some companies have separate job descriptions\n",
    "for AI engineering, as shown in the job headlines on LinkedIn\n",
    "from December 17, 2023.\n",
    "1. Three layers of the AI Stack\n",
    "There are three layers to any AI application stack: application development,\n",
    "model development, and infrastructure. When developing an AI application,\n",
    "you‚Äôll likely start from the top layer and move downwards as needed:\n",
    "Application development\n",
    "With models so readily available, anyone can use them to develop\n",
    "applications. This is the layer that has seen the most action in the last two\n",
    "years, and it‚Äôs still rapidly evolving. Application development involves\n",
    "providing a model with good prompts and necessary context. This layer\n",
    "requires rigorous evaluation and good applications demand good interfaces.\n",
    "Model development\n",
    "This layer provides tooling for developing models, including frameworks for\n",
    "modeling, training, fine-tuning, and inference optimization. Because data is\n",
    "central to model development, this layer also contains dataset engineering.\n",
    "Model development also requires rigorous evaluation.\n",
    "Infrastructure\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 7/22\n",
    "At the bottom of the stack is infrastructure, which includes tooling for model\n",
    "serving, managing data and compute, and monitoring.\n",
    "The three layers, and examples of responsibilities for each one, are shown\n",
    "below:\n",
    "Figure 1-14. Three layers of the AI engineering stack\n",
    "To get a sense of how the landscape has evolved with foundation models; in\n",
    "March 2024, I searched GitHub for all AI-related repositories with at least 500\n",
    "stars. Given the prevalence of GitHub, I believe this data is a good proxy for\n",
    "understanding the ecosystem. In my analysis, I also included repositories for\n",
    "applications and models, which are the products of the application\n",
    "development and model development layers, respectively. I found a total of\n",
    "920 repositories. Figure 1-15 shows the cumulative number of repositories in\n",
    "each category month by month.\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 8/22\n",
    "Figure 1-15. Cumulative count of repositories by category over\n",
    "time\n",
    "The data shows a big jump in the number of AI toolings in 2023, after the\n",
    "introduction of Stable Diffusion and ChatGPT. That year, the categories which\n",
    "saw the biggest increases were applications and application development.\n",
    "The infrastructure layer saw some growth, but much less than in other layers.\n",
    "This is expected: even though models and applications have changed, the\n",
    "core infrastructural needs of resource management, serving, monitoring, etc.,\n",
    "remain the same.\n",
    "This brings us to the next point. While the level of excitement and creativity\n",
    "around foundation models is unprecedented, many principles of building AI\n",
    "applications are unchanged. For enterprise use cases, AI applications still\n",
    "need to solve business problems, and, therefore, it‚Äôs still essential to map\n",
    "from business metrics to ML metrics, and vice versa, and you still need to do\n",
    "systematic experimentation. With classical ML engineering, you experiment\n",
    "with different hyperparameters. With foundation models, you experiment with\n",
    "different models, prompts, retrieval algorithms, sampling variables, and more.\n",
    "We still want to make models run faster and cheaper. It‚Äôs still important to set\n",
    "up a feedback loop so we can iteratively improve our applications with\n",
    "production data.\n",
    "This means that much of what ML engineers have learned and shared over\n",
    "the last decade is still applicable. This collective experience makes it easier\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 9/22\n",
    "for everyone to begin building AI applications. However, built on top of these\n",
    "enduring principles are many innovations unique to AI engineering.\n",
    "2.AI engineering versus ML engineering\n",
    "While the unchanging principles of deploying AI applications are reassuring,\n",
    "it‚Äôs also important to understand how things have changed. This is helpful for\n",
    "teams that want to adapt their existing platforms for new AI use cases, and\n",
    "for developers interested in which skills to learn in order to stay competitive in\n",
    "a new market.\n",
    "At a high level, building applications using foundation models today differs\n",
    "from traditional ML engineering in three major ways:\n",
    ". Without foundation models, you have to train your own models for\n",
    "applications. With AI engineering, you use a model someone else has\n",
    "trained. This means AI engineering focuses less on modeling and\n",
    "training, and more on model adaptation.\n",
    ". AI engineering works with models that are bigger, consume more\n",
    "compute resources, and incur higher latency than traditional ML\n",
    "engineering. This means there‚Äôs more pressure for efficient training and\n",
    "inference optimization. A corollary of compute-intensive models is that\n",
    "many companies now need more GPUs and work with bigger compute\n",
    "clusters than previously, which means there‚Äôs more need for engineers\n",
    "who know how to work with GPUs and big clusters [A head of AI at a\n",
    "Fortune 500 company told me his team knows how to work with 10\n",
    "GPUs, but not how to work with 1,000 GPUs.]\n",
    ". AI engineering works with models that can produce open-ended outputs,\n",
    "which provide models with the flexibility for more tasks, but are also\n",
    "harder to evaluate. This makes evaluation a much bigger problem in AI\n",
    "engineering.\n",
    "In short, AI engineering differs from ML engineering in that it‚Äôs less about\n",
    "model development, and more about adapting and evaluating models. I‚Äôve\n",
    "mentioned model adaptation several times, so before we move on, I want to\n",
    "ensure we‚Äôre on the same page about what ‚Äúmodel adaptation‚Äù means. In\n",
    "general, model adaptation techniques can be divided into two categories,\n",
    "depending on whether they require updating model weights:\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 10/22\n",
    "Prompt-based techniques, which includes prompt engineering, adapt a\n",
    "model without updating the model weights. You adapt a model by giving it\n",
    "instructions and context, instead of changing the model itself. Prompt\n",
    "engineering is easier to get started on and requires less data. Many\n",
    "successful applications have been built with just prompt engineering. Its ease\n",
    "of use allows you to experiment with more models, which increases the\n",
    "chance of finding a model that is unexpectedly good for an application.\n",
    "However, prompt engineering might not be enough for complex tasks, or\n",
    "applications with strict performance requirements.\n",
    "Fine-tuning, on the other hand, requires updating model weights. You\n",
    "adapt a model by making changes to the model itself. In general, fine-tuning\n",
    "techniques are more complicated and require more data, but they can\n",
    "significantly improve a model‚Äôs quality, latency, and cost. Many things aren‚Äôt\n",
    "possible without changing model weights, such as adapting a model to a new\n",
    "task it wasn‚Äôt exposed to during training.\n",
    "Now, let‚Äôs zoom into the application development and model development\n",
    "layers to see how each has changed with AI engineering, starting with what\n",
    "ML engineers are more familiar with. This section gives an overview of\n",
    "different processes involved in developing an AI application.\n",
    "Model development\n",
    "Model development is the layer most commonly associated with traditional\n",
    "ML engineering. It has three main responsibilities: modeling and training,\n",
    "dataset engineering, and inference optimization. Evaluation is also required\n",
    "because most people come across it first in the application development\n",
    "layer.\n",
    "Modeling and training\n",
    "Modeling and training refers to the process of coming up with a model\n",
    "architecture, training it, and fine-tuning it. Examples of tools in this category\n",
    "are Google‚Äôs TensorFlow, Hugging Face‚Äôs Transformers, and Meta‚Äôs PyTorch.\n",
    "Developing ML models requires specialized ML knowledge. It requires\n",
    "knowing different types of ML algorithms such as clustering, logistic\n",
    "regression, decision trees, and collaborative filtering, and also neural network\n",
    "architectures such as feedforward, recurrent, convolutional, and transformer.\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 11/22\n",
    "It also requires understanding of how a model learns, including concepts\n",
    "such as gradient descent, loss function, regularization, etc.\n",
    "With the availability of foundation models, ML knowledge is no longer a musthave for building AI applications. I‚Äôve met many wonderful, successful AI\n",
    "application builders who aren‚Äôt at all interested in learning about gradient\n",
    "descent. However, ML knowledge is still extremely valuable, as it expands the\n",
    "set of tools you can use, and helps with trouble-shooting when a model\n",
    "doesn‚Äôt work as expected.\n",
    "Differences between training, pre-training, fine-tuning, and\n",
    "post-training\n",
    "Training always involves changing model weights, but not all changes to\n",
    "model weights constitute training. For example, quantization, the process of\n",
    "reducing the precision of model weights, technically changes the model‚Äôs\n",
    "weight values but isn‚Äôt considered training.\n",
    "The term ‚Äútraining‚Äù can often be used in place of pre-training, finetuning, and\n",
    "post-training, which refer to different phases:\n",
    "Pre-training refers to training a model from scratch; the model weights are\n",
    "randomly initialized. For LLMs, pre-training often involves training a model for\n",
    "text completion. Out of all training steps, pre-training is often the most\n",
    "resource-intensive by a long shot. For the InstructGPT model, pre-training\n",
    "takes up to 98% of the overall compute and data resources. Pre-training also\n",
    "takes a long time. A small mistake during pre-training can incur a significant\n",
    "financial loss and set back a project significantly. Due to the resourceintensive nature of pre-training, it has become an art that only a few practice.\n",
    "Those with expertise in pre-training large models, however, are highly sought\n",
    "after [and attract incredible compensation packages].\n",
    "Fine-tuning means continuing to train a previously-trained model; model\n",
    "weights are obtained from the previous training process. Since a model\n",
    "already has certain knowledge from pre-training, fine-tuning typically requires\n",
    "fewer resources like data and compute than pre-training does.\n",
    "Post-training. Many people use post-training to refer to the process of\n",
    "training a model after the pre-training phase. Conceptually, post-training and\n",
    "fine-tuning are the same and can be used interchangeably. However,\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 12/22\n",
    "sometimes, people use them differently to signify the different goals. It‚Äôs\n",
    "usually post-training when done by model developers. For example, OpenAI\n",
    "might post-train a model to make it better at following instructions before\n",
    "releasing it.\n",
    "It‚Äôs fine-tuning when it‚Äôs done by application developers. For example, you\n",
    "might fine-tune an OpenAI model which has been post-trained in order to\n",
    "adapt it to your needs.\n",
    "Pre-training and post-training make up a spectrum, and their processes and\n",
    "toolings are very similar.\n",
    "[Footnote: If you think the terms ‚Äúpre-training‚Äù and ‚Äúpost-training‚Äù lack\n",
    "imagination, you‚Äôre not alone. The AI research community is great at many\n",
    "things, but naming isn‚Äôt one of them. We already talked about how ‚Äúlarge\n",
    "language model‚Äù is hardly a scientific term because of the ambiguity of the\n",
    "word ‚Äúlarge‚Äù. And I really wish people would stop publishing papers with the\n",
    "title ‚ÄúX is all you need.‚Äù]\n",
    "Some people use ‚Äútraining‚Äù to refer to prompt engineering, which isn‚Äôt correct.\n",
    "I read a Business Insider article in which the author said she‚Äôd trained\n",
    "ChatGPT to mimic her younger self. She did so by feeding her childhood\n",
    "journal entries into ChatGPT. Colloquially, the author‚Äôs usage of the ‚Äútraining‚Äù\n",
    "is correct, as she‚Äôs teaching the model to do something. But technically, if you\n",
    "teach a model what to do via the context input into it, then that is prompt\n",
    "engineering. Similarly, I‚Äôve seen people use ‚Äúfine-tuning‚Äù to describe prompt\n",
    "engineering.\n",
    "Dataset engineering\n",
    "Dataset engineering refers to curating, generating, and annotating data\n",
    "needed for training and adapting AI models.\n",
    "In traditional ML engineering, most use cases are close-ended: a model‚Äôs\n",
    "output can only be among predefined values. For example, spam\n",
    "classification with only two possible outputs of ‚Äúspam‚Äù and ‚Äúnot spam‚Äù, is\n",
    "close-ended. Foundation models, however, are open-ended. Annotating\n",
    "open-ended queries is much harder than annotating close-ended queries; it‚Äôs\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 13/22\n",
    "easier to determine whether an email is spam than it is to write an essay. So\n",
    "data annotation is a much bigger challenge for AI engineering.\n",
    "Another difference is that traditional ML engineering works more with tabular\n",
    "data, whereas foundation models work with unstructured data. In AI\n",
    "engineering, data manipulation is more about deduplication, tokenization,\n",
    "context retrieval, and quality control, including removing sensitive information\n",
    "and toxic data.\n",
    "Many people argue that because models are now commodities, data is the\n",
    "main differentiator, making dataset engineering more important than ever.\n",
    "How much data you need depends on the adapter technique you use.\n",
    "Training a model from scratch generally requires more data than fine-tuning\n",
    "does, which in turn requires more data than prompt engineering.\n",
    "Regardless of how much data you need, expertise in data is useful when\n",
    "examining a model, as its training data gives important clues about its\n",
    "strengths and weaknesses.\n",
    "Inference optimization\n",
    "Inference optimization means making models faster and cheaper. Inference\n",
    "optimization has always been important for ML engineering. Users never\n",
    "reject faster models, and companies can always benefit from cheaper\n",
    "inference. However, as foundation models scale up to incur ever-higher\n",
    "inference cost and latency, inference optimization has become even more\n",
    "important.\n",
    "One challenge of foundation models is that they are often autoregressive:\n",
    "tokens are generated sequentially. If it takes 10ms for a model to generate a\n",
    "token, it‚Äôll take a second to generate an output of 100 tokens, and even more\n",
    "for longer outputs. As users are notoriously impatient, getting AI applications‚Äô\n",
    "latency down to the 100ms latency expected of a typical internet application\n",
    "is a huge challenge. Inference optimization has become an active subfield in\n",
    "both industry and academia.\n",
    "A summary of how the importance of categories of model development\n",
    "changes with AI engineering:\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 14/22\n",
    "Table 1-4. How different responsibilities of model development\n",
    "have changed with foundation models\n",
    "3.Application development in AI engineering\n",
    "With traditional ML engineering where teams build applications using their\n",
    "proprietary models, the model quality is a differentiation. With foundation\n",
    "models, where many teams use the same model, differentiation must be\n",
    "gained through the application development process.\n",
    "The application development layer consists of these responsibilities:\n",
    "evaluation, prompt engineering, and AI interface.\n",
    "Evaluation\n",
    "Evaluation is about mitigating risks and uncovering opportunities, and is\n",
    "necessary throughout the whole model adaptation process. Evaluation is\n",
    "needed to select models, benchmark progress, determine whether an\n",
    "application is ready for deployment, and to detect issues and opportunities for\n",
    "improvement in production.\n",
    "While evaluation has always been important in ML engineering, it‚Äôs even\n",
    "more important with foundation models, for many reasons. To summarize,\n",
    "these challenges arise chiefly from foundation models‚Äô open-ended nature\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 15/22\n",
    "and expanded capabilities. For example, in close-ended ML tasks like fraud\n",
    "detection, there are usually expected ground truths which you can compare a\n",
    "model‚Äôs outputs against. If output differs from expected output, you know the\n",
    "model is wrong. For a task like chatbots, there are so many possible\n",
    "responses to each prompt that it is impossible to curate an exhaustive list of\n",
    "ground truths to compare a model‚Äôs response to.\n",
    "The existence of so many adaptation techniques also makes evaluation\n",
    "harder. A system that performs poorly with one technique might perform much\n",
    "better with another. When Google launched Gemini in December 2023, they\n",
    "claimed Gemini was better than ChatGPT in the MMLU benchmark\n",
    "(Hendrycks et al., 2020). Google had evaluated Gemini using a prompt\n",
    "engineering technique called CoT@32. In this technique, Gemini was shown\n",
    "32 examples, while ChatGPT was shown only 5 examples. When both were\n",
    "shown five examples, ChatGPT performed better, as shown below:\n",
    "Table 1-5. Different prompts can cause models to perform very\n",
    "differently, as seen on Gemini‚Äôs technical report (December\n",
    "2023)\n",
    "Prompt engineering and context construction\n",
    "Prompt engineering is about getting AI models to express desirable behaviors\n",
    "from the input alone, without changing the model weights. The Gemini\n",
    "evaluation story highlights the impact of prompt engineering on model\n",
    "performance. By using a different prompt engineering technique, Gemini\n",
    "Ultra‚Äôs performance on MMLU went from 83.7% to 90.04%.\n",
    "It‚Äôs possible to get a model to do amazing things with just prompts. The right\n",
    "instructions can get a model to perform a task you want in the format of your\n",
    "choice. Prompt engineering is not just about telling a model what to do. It‚Äôs\n",
    "also about giving the model the necessary context and tools for a given task.\n",
    "For complex tasks with long context, you might also need to provide the\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 16/22\n",
    "model with a memory management system, so the model can keep track of\n",
    "its history.\n",
    "AI interface\n",
    "AI interface means creating an interface for end users to interact with AI\n",
    "applications. Before foundation models, only organizations with sufficient\n",
    "resources to develop AI models could develop AI applications. These\n",
    "applications were often embedded into organizations‚Äô existing products. For\n",
    "example, fraud detection was embedded into Stripe, Venmo, and PayPal.\n",
    "Recommender systems were part of social networks and media apps like\n",
    "Netflix, TikTok, and Spotify.\n",
    "With foundation models, anyone can build AI applications. You can serve your\n",
    "AI applications as standalone products, or embed them into other products,\n",
    "including products developed by others. For example, ChatGPT and\n",
    "Perplexity are standalone products, whereas GitHub‚Äôs Copilot is commonly\n",
    "used as a plug-in in VSCode, while Grammarly is commonly used as a\n",
    "browser extension for Google Docs. Midjourney can be used via its\n",
    "standalone web app, or its integration in Discord.\n",
    "There needs to be tools that provide interfaces for standalone AI applications,\n",
    "or which make it easy to integrate AI into existing products. Here are some\n",
    "interfaces that are gaining popularity for AI applications:\n",
    "Standalone web, desktop, and mobile apps. [Streamlit, Gradio, and\n",
    "Plotly Dash are common tools for building AI web apps.]\n",
    "Browser extensions that let users quickly query AI models while\n",
    "browsing.\n",
    "Chatbots integrated into chat apps like Slack, Discord, WeChat, and\n",
    "WhatsApp.\n",
    "Many products, including VSCode, Shopify, and Microsoft 365, provide\n",
    "APIs that let developers integrate AI into their products as plug-ins and\n",
    "add-ons. These APIs can also be used by AI agents to interact with the\n",
    "world.\n",
    "While the chat interface is the most commonly used, AI interfaces can also be\n",
    "voice-based, such as voice assistants, or they can be embodied as with\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 17/22\n",
    "augmented and virtual reality.\n",
    "These new AI interfaces also mean new ways to collect and extract user\n",
    "feedback. The conversation interface makes it so much easier for users to\n",
    "give feedback in natural language, but this feedback is harder to extract.\n",
    "A summary of how the importance of different categories of app development\n",
    "changes with AI engineering:\n",
    "Table 1-6. The importance of different categories in app\n",
    "development for AI engineering and ML engineering\n",
    "4.AI Engineering versus full-stack\n",
    "engineering\n",
    "The increased emphasis on application development, especially on\n",
    "interfaces, brings AI engineering closer to full-stack development. [Footnote:\n",
    "7 Anton Bacaj told me: ‚ÄúAI engineering is just software engineering with AI\n",
    "models thrown in the stack.‚Äù]\n",
    "The growing importance of interfaces leads to a shift in the design of AI\n",
    "toolings to attract more frontend engineers. Traditionally, ML engineering is\n",
    "Python-centric. Before foundation models, the most popular ML frameworks\n",
    "supported mostly Python APIs. Today, Python is still popular, but there is also\n",
    "increasing support for JavaScript APIs, with LangChain.js, Transformers.js,\n",
    "OpenAI‚Äôs Node library, and Vercel‚Äôs AI SDK.\n",
    "While many AI engineers come from traditional ML backgrounds, more\n",
    "increasingly come from web development or full-stack backgrounds. An\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 18/22\n",
    "advantage that full-stack engineers have over traditional ML engineers is their\n",
    "ability to quickly turn ideas into demos, get feedback, and iterate.\n",
    "With traditional ML engineering, you usually start with gathering data and\n",
    "training a model. Building the product comes last. However, with AI models\n",
    "readily available today, it‚Äôs possible to start with building the product first, and\n",
    "only invest in data and models once the product shows promise, as\n",
    "visualized in Figure 1-16.\n",
    "Figure 1-16. The new AI engineering workflow rewards those\n",
    "who can iterate fast. Image recreated from ‚ÄúThe Rise of the AI\n",
    "Engineer‚Äù (Shawn Wang, 2023).\n",
    "In traditional ML engineering, model development and product development\n",
    "are often disjointed processes, with ML engineers rarely involved in product\n",
    "decisions at many organizations. However, with foundation models, AI\n",
    "engineers tend to be much more involved in building the product.\n",
    "Summary\n",
    "I intend this chapter to serve two purposes. One is to explain the emergence\n",
    "of AI engineering as a discipline, thanks to the availability of foundation\n",
    "models. The second is to give an overview of the process of building\n",
    "applications on top of these models. I hope this chapter achieves this. As an\n",
    "overview, it only lightly touches on many concepts, which are explored further\n",
    "in the book.\n",
    "The rapid growth of AI engineering is motivated by the many applications\n",
    "enabled by the emerging capabilities of foundation models. We‚Äôve covered\n",
    "some of the most successful application patterns, for both consumers and\n",
    "enterprises. Despite the incredible number of AI applications already in\n",
    "production, we‚Äôre still in the early stages of AI engineering, with countless\n",
    "more innovations yet to be built.\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 19/22\n",
    "While AI engineering is a new term, it has evolved out of ML engineering,\n",
    "which is the overarching discipline involved in building applications with all ML\n",
    "models. Many principles of ML engineering are applicable to AI engineering.\n",
    "However, AI engineering also brings new challenges and solutions.\n",
    "One aspect of AI engineering that is challenging to capture in words is the\n",
    "incredible collective energy, creativity, and engineering talent of the\n",
    "community. This enthusiasm can often be overwhelming, as it‚Äôs impossible to\n",
    "keep up-to-date with new techniques, discoveries, and engineering feats that\n",
    "seem to happen constantly.\n",
    "One consolation is that since AI is great at information aggregation, it can\n",
    "help us aggregate and summarize all these new updates! But tools can help\n",
    "only to a certain extent; the more overwhelming a space is, the more\n",
    "important it is to have a framework to help navigate it. This book aims to\n",
    "provide such a framework.\n",
    "The rest of the book explores this framework step-by-step, starting with the\n",
    "fundamental building block of AI engineering: foundation models that make so\n",
    "many amazing applications possible.\n",
    "Gergely, again. Thanks, Chip, for sharing this excerpt. To go deeper in this\n",
    "topic, consider picking up her book, AI Engineering, in which many topics\n",
    "mentioned in this article are covered in greater depth, including:\n",
    "Sampling variables are discussed in Chapter 2\n",
    "Pre-training and post-training differences are explored further in\n",
    "Chapters 2 and 7\n",
    "The challenges of evaluating foundation models are discussed in\n",
    "Chapter 3\n",
    "Chapter 5 discusses prompt engineering, and Chapter 6 discusses\n",
    "context construction\n",
    "Inference optimization techniques, including quantization, distillation,\n",
    "and parallelism, are discussed in Chapters 7 through 9\n",
    "Dataset engineering is the focus of Chapter 8\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 20/22\n",
    "User feedback design is discussed in Chapter 10\n",
    "‚ÄúAI Engineering‚Äù is surprisingly easy for software engineers to pick up.\n",
    "When LLMs went mainstream in late 2022, I briefly assumed that to work in\n",
    "the AI field, one needed to be an ML researcher. This is still true if you want to\n",
    "work in areas like foundational model research. However, most AI\n",
    "engineering positions at startups, scaleups and Big Tech, are about building\n",
    "AI applications on top of AI APIs, or self-hosted LLMs.\n",
    "Most of the complexity lies in the building of applications, not the LLM model\n",
    "part. That‚Äôs not to say there are not a bunch of new things to learn in order to\n",
    "become a standout AI engineer, but it‚Äôs still very much doable, and many\n",
    "engineers are making the switch.\n",
    "I hope you enjoyed this summary of the AI engineering stack. For more\n",
    "deepdives on AI engineering, check out:\n",
    "AI Engineering in the real world ‚Äì Hands-on examples and learnings\n",
    "from software engineers turned ‚ÄúAI engineers‚Äù at seven companies\n",
    "Building, launching, and scaling ChatGPT Images ‚Äì ChatGPT\n",
    "Images became one of the largest AI engineering projects in the world,\n",
    "overnight. But how was it built? A deepdive with OpenAI‚Äôs engineering\n",
    "team\n",
    "Building Windsurf ‚Äì the engineering challenges of building an AI\n",
    "product serving hundreds of billions of tokens per day.\n",
    "AI Engineering with Chip Huyen ‚Äì What is AI engineering, and how to\n",
    "get started with it? Podcast with Chip.\n",
    "A guest post by\n",
    "Chip Huyen\n",
    "I work at the intersection of AI, education, and storytelling. I help\n",
    "companies deploy AI applications in production. I'm the author of\n",
    "Designing Machine Learning Systems and AI Engineering, but I\n",
    "also write novels and stuff.\n",
    "Subscribe to Chip\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 21/22\n",
    "You‚Äôre on the free list for The Pragmatic Engineer. For the full\n",
    "experience, become a paying subscriber. Many readers expense this\n",
    "newsletter within their company‚Äôs training/learning/development budget.\n",
    "Upgrade to paid\n",
    "This post is public, so feel free to share and forward it.\n",
    "Share The Pragmatic Engineer\n",
    "If you enjoyed this post, you might enjoy my book, The Software Engineer's\n",
    "Guidebook. Here is what Tanya Reilly, senior principal engineer and author\n",
    "of The Staff Engineer's Path said about it:\n",
    "\"From performance reviews to P95 latency, from team dynamics to\n",
    "testing, Gergely demystifies all aspects of a software career. This book is\n",
    "well named: it really does feel like the missing guidebook for the\n",
    "whole industry.\"\n",
    "Get The Software Engineer's Guidebook\n",
    "LIKE COMMENT RESTACK\n",
    "¬© 2025 Gergely Orosz\n",
    "548 Market Street PMB 72296, San Francisco, CA 94104\n",
    "Unsubscribe\n",
    "6/4/25, 8:41 PM Gmail - The AI Engineering Stack\n",
    "https://mail.google.com/mail/u/0/?ik=6c5510f221&view=pt&search=all&permthid=thread-f:1832653853260371304&simpl=msg-f:1832653853260371304 22/22\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "\n",
    "# Step 4: print the result\n",
    "summary = response.choices[0].message.content\n",
    "display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed9f14-b349-40e9-a42c-b367e77f8bda",
   "metadata": {},
   "source": [
    "## An extra exercise for those who enjoy web scraping\n",
    "\n",
    "You may notice that if you try `display_summary(\"https://openai.com\")` - it doesn't work! That's because OpenAI has a fancy website that uses Javascript. There are many ways around this that some of you might be familiar with. For example, Selenium is a hugely popular framework that runs a browser behind the scenes, renders the page, and allows you to query it. If you have experience with Selenium, Playwright or similar, then feel free to improve the Website class to use them. In the community-contributions folder, you'll find an example Selenium solution from a student (thank you!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab24dc-5f90-4570-b542-b0585aca3eb6",
   "metadata": {},
   "source": [
    "# Sharing your code\n",
    "\n",
    "I'd love it if you share your code afterwards so I can share it with others! You'll notice that some students have already made changes (including a Selenium implementation) which you will find in the community-contributions folder. If you'd like add your changes to that folder, submit a Pull Request with your new versions in that folder and I'll merge your changes.\n",
    "\n",
    "If you're not an expert with git (and I am not!) then GPT has given some nice instructions on how to submit a Pull Request. It's a bit of an involved process, but once you've done it once it's pretty clear. As a pro-tip: it's best if you clear the outputs of your Jupyter notebooks (Edit >> Clean outputs of all cells, and then Save) for clean notebooks.\n",
    "\n",
    "Here are good instructions courtesy of an AI friend:  \n",
    "https://chatgpt.com/share/677a9cb5-c64c-8012-99e0-e06e88afd293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4484fcf-8b39-4c3f-9674-37970ed71988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
